# 6. 파일 시스템 접근하기

- `fs` 모듈은 파일 시스템에 접근하는 모듈이다.
- 간단한 예제를 통해 사용 방법을 알아본다.

```txt
// readme.txt
저를 읽어주세요.
```

```js
// readFile.js
const fs = require('fs');

fs.readFile('./readme.txt', (err, data) => {
    if (err) {
        throw err;
    }
    console.log(data);
    console.log(data.toString());
});
```

```zsh
$ node readFile
<Buffer ec a0 80 eb a5 bc 20 ec 9d bd ec 96 b4 ec a3 bc ec 84 b8 ec 9a 94 2e>
저를 읽어주세요.
```

- `readFile`의 결과물은 버퍼(`Buffer`)라는 형태로 제공된다.
    - 버퍼는 메모리의 데이터다.
- `fs`는 기본적으로 콜백 형식의 모듈이므로 프로미스 형식으로 바꿔주는 방법을 사용한다.

```js
// readFilePromise.js
const fs = require('fs').promises;

fs.readFile('./readme.txt')
    .then(data => {
        console.log(data);
        console.log(data.toString());
    })
    .catch(err => {
        console.error(err);
    });
```

- 이번에는 파일을 작성한다.

```js
// writeFile.js
const fs = require('fs').promises;

fs.writeFile('./writeme.txt', '글이 입력됩니다')
    .then(() => {
        return fs.readFile('./writeme.txt');
    })
    .then(data => {
        console.log(data.toString());
    })
    .catch(err => {
        console.error(err);
    });
```

```zsh
$ node writeFile
글이 입력됩니다
```

## 6.1 동기 메서드와 비동기 메서드

- `setTimeout` 같은 타이머와 `process.nextTick` 외에도 노드는 대부분의 메서드를 비동기 방식으로 처리한다.
- 하지만 몇몇 메서드는 동기 방식으로도 사용할 수 있다.
- 특히 `fs` 모듈이 그런 메서드를 많이 가지고 있다.

```txt
// readme2.txt
저를 여러 번 읽어보세요.
```

```js
// async.js
const fs = require('fs');

console.log('시작');
fs.readFile('./readme2.txt', (err, data) => {
    if (err) {
        throw err;
    }
    console.log('1번', data.toString());
});
fs.readFile('./readme2.txt', (err, data) => {
    if (err) {
        throw err;
    }
    console.log('2번', data.toString());
});
fs.readFile('./readme2.txt', (err, data) => {
    if (err) {
        throw err;
    }
    console.log('3번', data.toString());
});
console.log('끝');
```

```zsh
$ node async
시작
끝
1번 저를 여러 번 읽어보세요.
3번 저를 여러 번 읽어보세요.
2번 저를 여러 번 읽어보세요.
```

- 시작과 끝을 제외하고는 결과의 순서가 매번 달라진다.
- 비동기 메서드는 **백그라운드에 해당 파일을 읽으라고 요청하고 다음 작업으로 넘어**간다.
- 이러한 방식은 수백 개의 I/O 요청이 들어와도 백그라운드에 위임하므로 상당히 좋다.
- 동기와 비동기, 블로킹과 논 블로킹은 노드에서 혼용되나 의미가 서로 다르다.
    - 동기와 비동기: 백그라운드 작업 완료 확인 여부
    - 블로킹과 논 블로킹: 함수가 바로 return되는지 여부
- 순서대로 처리하고 싶다면 다음 메서드를 사용하면 된다.

```js
// sync.js
const fs = require('fs');

console.log('시작');
let data = fs.readFileSync('./readme2.txt');
console.log('1번', data.toString());
data = fs.readFileSync('./readme2.txt');
console.log('2번', data.toString());
data = fs.readFileSync('./readme2.txt');
console.log('3번', data.toString());
console.log('끝');
```

```zsh
$ node sync
시작
1번 저를 여러 번 읽어보세요.
2번 저를 여러 번 읽어보세요.
3번 저를 여러 번 읽어보세요.
끝
```

- 위와 같은 동기 코드는 이해하기 쉽지만, 요청이 많을 경우 성능 문제가 발생한다.
    - 이전 작업이 완료되어야만 다음 작업을 진행할 수 있기 때문이다.
- 대부분의 경우 비동기 메서드를 권장하며, 동기 메서드는 초기화 용도로만 사용하는 것이 좋다.
- 비동기 방식으로 순서를 유지하려면 다음과 같이 하면 된다.

```js
// asyncOrder.js
const fs = require('fs');

console.log('시작');
fs.readFile('./readme2.txt', (err, data) => {
    if (err) {
        throw err;
    }
    console.log('1번', data.toString());
    fs.readFile('./readme2.txt', (err, data) => {
        if (err) {
            throw err;
        }
        console.log('2번', data.toString());
        fs.readFile('./readme2.txt', (err, data) => {
            if (err) {
                throw err;
            }
            console.log('3번', data.toString());
            console.log('끝');
        });
    });
});
```

```zsh
$ node asyncOrder
시작
1번 저를 여러 번 읽어보세요.
2번 저를 여러 번 읽어보세요.
3번 저를 여러 번 읽어보세요.
끝
```

- 콜백 지옥이 펼쳐지지만 순서가 어긋나지는 않는다.
- 콜백 지옥은 `Promise`나 `async/await`로 어느 정도 해결할 수 있다.

```js
// asyncOrderPromise.js
const fs = require('fs').promises;

console.log('시작');
fs.readFile('./readme2.txt')
    .then(data => {
        console.log('1번', data.toString());
        return fs.readFile('./readme2.txt');
    })
    .then(data => {
        console.log('2번', data.toString());
        return fs.readFile('./readme2.txt');
    })
    .then(data => {
        console.log('3번', data.toString());
        console.log('끝');
    })
    .catch(err => {
        console.error(err);
    });
```

## 6.2 버퍼와 스트림 이해하기

- 파일을 읽거나 쓰는 방식에는 크게 두 가지가 존재한다.
    - 버퍼를 이용하는 방식
    - 스트림을 이용하는 방식
- `readFile` 메서드를 사용하여 읽었던 파일이 버퍼 형식으로 출력되었다.
    - 노드는 파일을 읽을 때 메모리에 파일 크기만큼 공간을 마련해둔다.
    - 그리고 파일 데이터를 메모리에 저장한 뒤 사용자가 조작할 수 있게 한다.
    - 이 때 메모리에 저장된 데이터가 **버퍼**다.

```js
// buffer.js
const buffer = Buffer.from('저를 버퍼로 바꿔보세요');
console.log('from():', buffer);
console.log('length:', buffer.length);
console.log('toString():', buffer.toString());

const array = [Buffer.from('띄엄'), Buffer.from('띄엄'), Buffer.from('띄어쓰기')];
const buffer2 = Buffer.concat(array);
console.log('concat():', buffer2.toString());

const buffer3 = Buffer.alloc(5);
console.log('alloc():', buffer3);
```

```zsh
$ node buffer
from(): <Buffer ec a0 80 eb a5 bc 20 eb b2 84 ed 8d bc eb a1 9c 20 eb b0 94 ea bf 94 eb b3 b4 ec 84 b8 ec 9a 94>
length: 32
toString(): 저를 버퍼로 바꿔보세요
concat(): 띄엄띄엄띄어쓰기
alloc(): <Buffer 00 00 00 00 00>
```

- `readFile` 방식의 버퍼가 편리하지만, 예를 들어 용량이 100MB인 파일이 있으면 버퍼도 100MB가 돼야 한다.
- 이는 서버 같이 몇 명이 사용할지 모르는 환경에선 메모리 문제가 발생할 수 있다.
- 그래서 버퍼의 크기를 작게 만든 후 여러 번 나눠 보내는 방식이 등장했다.
- 이를 편리하게 만든 것이 **스트림**이다.

```txt
// readme3.txt
저는 조금씩 조금씩 나눠서 전달됩니다. 나눠진 조각을 chunk라고 부릅니다.
```

```js
// createReadStream.js
const fs = require('fs');

const readStream = fs.createReadStream('./readme3.txt', { highWaterMark: 16 });
const data = [];

readStream.on('data', chunk => {
    data.push(chunk);
    console.log('data:', chunk, chunk.length);
});

readStream.on('end', () => {
    console.log('end:', Buffer.concat(data).toString());
});

readStream.on('error', err => {
    console.log('error:', err);
});
```

```zsh
$ node createReadStream    
data: <Buffer ec a0 80 eb 8a 94 20 ec a1 b0 ea b8 88 ec 94 a9> 16
data: <Buffer 20 ec a1 b0 ea b8 88 ec 94 a9 20 eb 82 98 eb 88> 16
data: <Buffer a0 ec 84 9c 20 ec a0 84 eb 8b ac eb 90 a9 eb 8b> 16
data: <Buffer 88 eb 8b a4 2e 20 eb 82 98 eb 88 a0 ec a7 84 20> 16
data: <Buffer ec a1 b0 ea b0 81 ec 9d 84 20 63 68 75 6e 6b eb> 16
data: <Buffer 9d bc ea b3 a0 20 eb b6 80 eb a6 85 eb 8b 88 eb> 16
data: <Buffer 8b a4 2e> 3
end: 저는 조금씩 조금씩 나눠서 전달됩니다. 나눠진 조각을 chunk라고 부릅니다.
```

- `createReadStream`의 두 번째 인수는 옵션 객체인데, `highWaterMark`는 버퍼의 크기를 정하는 옵션이다.
    - 기본값은 64KB지만 여러 번 나눠 보내는 모습을 보기 위해 16B로 낮췄다.

```js
// createWriteStream.js
const fs = require('fs');

const writeStream = fs.createWriteStream('./writeme2.txt');
writeStream.on('finish', () => {
    console.log('파일 쓰기 완료');
});

writeStream.write('이 글을 씁니다.\n');
writeStream.write('한 번 더 씁니다.');
writeStream.end();
```

```zsh
$ node createWriteStream
파일 쓰기 완료
```

- `createReadStream`으로 파일을 읽고 그 스트림을 전달 받아 `createWriteStream`으로 파일을 쓸 수 있다.
- 스트림끼리 연결하는 것을 '파이핑한다'고 표현한다.

```txt
// readme4.txt
저를 writeme3.txt로 보내주세요
```

```js
// pipe.js
const fs = require('fs');

const readStream = fs.createReadStream('./readme4.txt');
const writeStream = fs.createWriteStream('writeme3.txt');
readStream.pipe(writeStream);
```

```zsh
$ node pipe
# writeme3.txt 생성
```

- `readme4.txt`와 똑같은 내용이 `writeme3.txt`로 생성되었다.
- `pipe`는 스트림 사이에 여러 번 연결할 수 있습니다.
- 다음 코드는 파일을 읽은 후 gzip 방식으로 압축하는 코드다.

```js
// gzip.js
const zlib = require('zlib');
const fs = require('fs');

const readStream = fs.createReadStream('./readme4.txt');
const zlibStream = zlib.createGzip();
const writeStream = fs.createWriteStream('./readme4.txt.gz');
readStream.pipe(zlibStream).pipe(writeStream);
```

```zsh
$ node gzip
# readme4.txt.gz 생성
```

- 다음으로는 1GB 용량의 텍스트 파일을 만들어본다.

```js
// createBigFile.js
const fs = require('fs');
const file = fs.createWriteStream('./big.txt');

for (let i = 0; i <= 10000000; i++) {
    file.write('안녕하세요. 엄청나게 큰 파일을 만들어 볼 것입니다. 각오 단단히 하세요!\n');
}
file.end();
```

- 실행해서 파일을 만들고 난 뒤, 아래 코드를 이용해 `readFileSync`로 파일을 복사해본다.

```js
// buffer-memory.js
const fs = require('fs');

console.log('before:', process.memoryUsage().rss);

const data1 = fs.readFileSync('./big.txt');
fs.writeFileSync('./big2.txt', data1);
console.log('buffer:', process.memoryUsage().rss);
```

```zsh
$ node buffer-memory
before: 18739200
buffer: 1019662336
```

- 순식간에 메모리 사용량이 1GB를 넘었는데, 복사를 위해 메모리에 파일을 모두 올려두었기 때문이다.
- 이번엔 스트림을 사용해서 복사해본다.

```js
// stream-memory.js
const fs = require('fs');

console.log('before:', process.memoryUsage().rss);

const readStream = fs.createReadStream('./big.txt');
const writeStream = fs.createWriteStream('./big3.txt');
readStream.pipe(writeStream);
readStream.on('end', () => {
    console.log('stream:', process.memoryUsage().rss);
});
```

```zsh
$ node stream-memory
before: 18821120
stream: 33505280
```

- 이전 방식보다 효과적으로 데이터를 전송한 사실을 확인했다.

-----
[HOME](./index.md)